{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323b8ff3-8c07-47a0-ae7e-4456124cade9",
   "metadata": {},
   "source": [
    "### Read in data\n",
    "\n",
    "The purpose of this notebook is to read in the raw data files (coming from the VR/eyetracking data file).\n",
    "Another helper-file contains a list of the videos, providing us with the order in which the videos appeared.\n",
    "\n",
    "#### load relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713e0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "def fill_nan(A):\n",
    "    '''\n",
    "    interpolate to fill nan values\n",
    "    '''\n",
    "    inds = np.arange(A.shape[0])\n",
    "    good = np.where(np.isfinite(A))\n",
    "    f = interpolate.interp1d(inds[good], A[good],bounds_error=False)\n",
    "    B = np.where(np.isfinite(A),A,f(inds))\n",
    "    return B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85cb9c8-5e51-40d2-ae11-d7997da268d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.12 (main, Jul  5 2023, 15:02:25) [Clang 14.0.6 ]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b54f3065-2506-4901-a698-29ea3ed0f61a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/schmaelz/miniconda3/envs/vr_pupil_study_env/bin/python'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72d099",
   "metadata": {},
   "source": [
    "#### setup vars and subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "360cffd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  39   78  117  156  195  234  273  312  351  390  429  468  507  546\n",
      "  585  624  663  702  741  780  819  858  897  936  975 1014 1053 1092\n",
      " 1131 1170]\n",
      "59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sub001', 'sub002', 'sub003']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_onset_times = (np.arange(39,1200,39))\n",
    "print(video_onset_times)\n",
    "\n",
    "folders = glob.glob(\"../data/00_raw_data/sub*\")\n",
    "folders.sort()\n",
    "subjs = []\n",
    "for f in folders:\n",
    "    subjs.append(f[-6:])\n",
    "\n",
    "print(len(subjs))\n",
    "subjs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e627e",
   "metadata": {},
   "source": [
    "#### read in files\n",
    "\n",
    "we loop over subjects, read in each subject's eye-tracking file, parse the file based on each video onset, assign the video's names, and save everything to a new folder \"parsed_video_data\". In that folder, we'll have for every subject (folders) that subject's individual video-files, specifically a time-code and a pupil-dilation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dde12a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub001\n",
      "sub002\n",
      "sub003\n",
      "sub004\n",
      "sub005\n",
      "sub006\n",
      "sub007\n",
      "sub008\n",
      "sub009\n",
      "sub010\n",
      "sub011\n",
      "sub012\n",
      "sub013\n",
      "sub014\n",
      "sub015\n",
      "sub016\n",
      "sub017\n",
      "sub018\n",
      "sub019\n",
      "sub020\n",
      "sub021\n",
      "sub022\n",
      "sub023\n",
      "sub024\n",
      "sub025\n",
      "sub026\n",
      "sub027\n",
      "sub028\n",
      "sub029\n",
      "sub030\n",
      "sub031\n",
      "sub032\n",
      "sub033\n",
      "sub034\n",
      "sub035\n",
      "sub037\n",
      "sub038\n",
      "sub039\n",
      "sub040\n",
      "sub041\n",
      "sub042\n",
      "sub043\n",
      "sub044\n",
      "sub045\n",
      "sub046\n",
      "sub047\n",
      "sub048\n",
      "sub049\n",
      "sub050\n",
      "sub051\n",
      "sub052\n",
      "sub053\n",
      "sub054\n",
      "sub055\n",
      "sub056\n",
      "sub057\n",
      "sub058\n",
      "sub059\n",
      "sub060\n"
     ]
    }
   ],
   "source": [
    "for curr_sub in range(len(subjs)):\n",
    "\n",
    "    print(subjs[curr_sub])\n",
    "\n",
    "    # assemble filepaths for the subjects\n",
    "    curr_sub_eye_file      = '../data/00_raw_data/' + subjs[curr_sub] + '/'+ subjs[curr_sub] +'_tracking_data_trial_1.txt'\n",
    "\n",
    "    #read in fixation information\n",
    "    eye_df = pd.read_csv(curr_sub_eye_file, sep = '\\t')\n",
    "    eye_df = eye_df.drop(['Unnamed: 9'], axis=1)\n",
    "    eye_df.head()\n",
    "    \n",
    "    \n",
    "    curr_sub_video_file      = '../data/00_raw_data/' + subjs[curr_sub] + '/'+ subjs[curr_sub] +'_videolist.csv'\n",
    "    video_file_names = pd.read_csv(curr_sub_video_file)\n",
    "\n",
    "    #video started: C:/Users/CAS.CARISMA/Desktop/VR-Video/resources/stimuli/commercial_cookies_30s_100.mp4\n",
    "    #select fixations and count them\n",
    "    #contain_values = eye_df[eye_df['flag    '].str.contains('video started')]\n",
    "    #contain_values.head()\n",
    "\n",
    "    #for row in contain_values.itertuples():\n",
    "    for curr_video in range(30):\n",
    "\n",
    "        #print(curr_video)\n",
    "        curr_video_name = video_file_names['filename'][curr_video]\n",
    "        #print(curr_video_name)\n",
    "\n",
    "        #curr_video_onset  = contain_values['seconds '].iloc[0]\n",
    "        curr_video_onset  = eye_df.iloc[(eye_df['seconds '] - video_onset_times[curr_video]).abs().argsort()[0],:]['seconds ']\n",
    "        curr_video_offset = curr_video_onset + 39\n",
    "\n",
    "        #current_video_name = contain_values['flag    '].iloc[0].replace('video started: C:/Users/CAS.CARISMA/Desktop/VR-Video/resources/stimuli/', '')[:-4]\n",
    "        #print(current_video_name)\n",
    "        current_video_name = curr_video_name[:-4] #+ str(curr_video)\n",
    "\n",
    "        out_path = '../data/01_parsed_video_data/' + subjs[curr_sub] + '/'\n",
    "        out_file_name          = out_path  + current_video_name + '.csv'  #\n",
    "\n",
    "        isExist = os.path.exists(out_path)\n",
    "        if not isExist:\n",
    "           os.makedirs(out_path)\n",
    "\n",
    "        #eye_df[eye_df['seconds '] == contain_values['seconds '].iloc[0]]\n",
    "\n",
    "        curr_video_df = eye_df[ eye_df['seconds '].between(curr_video_onset, curr_video_offset)]\n",
    "        #curr_video_df['pupil diameter'].plot()\n",
    "\n",
    "        curr_video_df['seconds '] = curr_video_df['seconds '] - curr_video_df['seconds '].iloc[0]\n",
    "\n",
    "        curr_video_df['pupil diameter'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "\n",
    "        curr_video_df['time'] = pd.to_datetime(curr_video_df['seconds '], unit='s')#.apply(lambda x: x.time())\n",
    "        #curr_video_df\n",
    "        curr_video_df = curr_video_df.set_index('time')\n",
    "        curr_video_df\n",
    "\n",
    "        curr_video_df = curr_video_df[~curr_video_df.index.duplicated(keep='first')]\n",
    "\n",
    "        curr_video_df_resampled = curr_video_df.resample('50ms').ffill()\n",
    "\n",
    "        curr_video_df_resampled['seconds_resampled'] = curr_video_df_resampled.index\n",
    "        curr_video_df_resampled['seconds_resampled'] = curr_video_df_resampled['seconds_resampled'] - curr_video_df_resampled['seconds_resampled'][0]\n",
    "\n",
    "        curr_video_df_resampled['time'] = curr_video_df_resampled['seconds_resampled'].dt.total_seconds()\n",
    "        curr_video_df_resampled.drop(columns = ['seconds_resampled', 'seconds ', 'position x', 'position y', 'position z' ], inplace =True)\n",
    "        curr_video_df_resampled.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        order = [5,0,1,2,3,4] # setting column's order\n",
    "        curr_video_df_resampled = curr_video_df_resampled[[curr_video_df_resampled.columns[i] for i in order]]\n",
    "\n",
    "\n",
    "        curr_video_df_resampled.to_csv(out_file_name, index=False)\n",
    "        del curr_video_df_resampled, curr_video_df\n",
    "    del eye_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ace748-8c62-4043-b813-a89158b9837d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
